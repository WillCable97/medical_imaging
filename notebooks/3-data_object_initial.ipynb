{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../\"\n",
    "root_dir = os.path.abspath(root_dir)\n",
    "data_path = os.path.join(root_dir, \"data\")\n",
    "processed_path = os.path.join(data_path, \"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list =[os.path.join(processed_path, x) for x in os.listdir(processed_path)]\n",
    "file_list = file_list[1:]#.gitkeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord_fn(example_proto):\n",
    "    feature_description = {\n",
    "        'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    height = tf.cast(example['height'], tf.int32)\n",
    "    width = tf.cast(example['width'], tf.int32)\n",
    "    depth = tf.cast(example['depth'], tf.int32)\n",
    "    label = tf.cast(example['label'], tf.int32)\n",
    "\n",
    "    image_raw = tf.io.decode_raw(example['image_raw'], tf.int32)\n",
    "    image = tf.reshape(image_raw, (height, width, depth))\n",
    "    \n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_set = tf.data.TFRecordDataset(file_list)\n",
    "tf_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(None, None, None), dtype=tf.int32, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_set = tf_set.map(parse_tfrecord_fn)\n",
    "tf_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 38)\n",
      "(256, 256, 38)\n",
      "(256, 256, 38)\n"
     ]
    }
   ],
   "source": [
    "# Create an iterator and get the next element\n",
    "iterator = iter(tf_set)\n",
    "for i in range(3):\n",
    "    image, label = iterator.get_next()\n",
    "    print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, None, None, None), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_set=tf_set.shuffle(1000).batch(64)\n",
    "tf_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "class DenseOutput(keras.layers.Layer):\n",
    "    def __init__(self, output_classes:int):\n",
    "        super().__init__()\n",
    "        self.flatten_layer = keras.layers.Flatten()\n",
    "        self.dense_1 = keras.layers.Dense(4096, activation='relu')\n",
    "        self.dense_2 = keras.layers.Dense(4096, activation='relu')\n",
    "        self.output_layer = keras.layers.Dense(output_classes, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.flatten_layer(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvComponent(keras.layers.Layer):\n",
    "    def __init__(self, channel_count: int):\n",
    "        super().__init__()\n",
    "        self.conv_1 = keras.layers.Conv2D(channel_count, (3, 3), activation='relu', padding='same')\n",
    "        self.conv_2 = keras.layers.Conv2D(channel_count, (3, 3), activation='relu', padding='same')\n",
    "        self.pool_layer = keras.layers.MaxPooling2D((2,2), strides=(2,2))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.pool_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg16(keras.Model):\n",
    "    def __init__(self, output_classes:int):\n",
    "        super().__init__()\n",
    "        self.initial_pool = keras.layers.MaxPooling2D((5, 5), strides=(5, 5))\n",
    "        self.comp_1 = ConvComponent(64)\n",
    "        self.comp_2 = ConvComponent(128)\n",
    "        self.comp_3 = ConvComponent(256) #all these have only 2 components (slight deviation)\n",
    "        self.comp_4 = ConvComponent(512)\n",
    "        self.comp_5 = ConvComponent(512)\n",
    "        self.connected_layer = DenseOutput(output_classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = self.initial_pool(inputs)\n",
    "        inputs = self.comp_1(inputs)\n",
    "        inputs = self.comp_2(inputs)\n",
    "        inputs = self.comp_3(inputs)\n",
    "        inputs = self.comp_4(inputs)\n",
    "        inputs = self.comp_5(inputs)\n",
    "        inputs = self.connected_layer(inputs)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Vgg16(4)\n",
    "A.compile(\"adam\", keras.losses.SparseCategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Vgg16.call().\n\n\u001b[1mInput 0 of layer \"max_pooling2d_6\" is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (None, None, None)\u001b[0m\n\nArguments received by Vgg16.call():\n  • inputs=tf.Tensor(shape=(None, None, None), dtype=int32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\willi\\Anaconda3\\envs\\Medical_Env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m, in \u001b[0;36mVgg16.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m---> 13\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomp_1(inputs)\n\u001b[0;32m     15\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomp_2(inputs)\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Vgg16.call().\n\n\u001b[1mInput 0 of layer \"max_pooling2d_6\" is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (None, None, None)\u001b[0m\n\nArguments received by Vgg16.call():\n  • inputs=tf.Tensor(shape=(None, None, None), dtype=int32)"
     ]
    }
   ],
   "source": [
    "A.fit(tf_set[tf.newaxis, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Medical_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
