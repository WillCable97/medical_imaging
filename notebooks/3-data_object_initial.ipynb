{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pydicom as dicom\n",
    "import cv2\n",
    "\n",
    "\n",
    "data_path = \"./data\"\n",
    "data_path = os.path.abspath(data_path)\n",
    "file_path = os.path.join(data_path, \"raw\", \"med_records\")\n",
    "processed_path = os.path.join(data_path, \"processed\")\n",
    "\n",
    "def extract_full_files_paths(raw_path: str, file_name: str, processed_path: str):\n",
    "    dframe = pd.read_csv(os.path.join(raw_path, file_name))\n",
    "    path_list = dframe['File Location'].to_list()\n",
    "    diagnostic_flag = dframe['3rd Party Analysis'].to_list()\n",
    "\n",
    "    diagnostic_flag = [0 if x==\"NO\" else 1 for x in diagnostic_flag]\n",
    "    path_list = [os.path.join(raw_path, x, \"1-1.dcm\") for x in path_list]\n",
    "\n",
    "    return path_list, diagnostic_flag\n",
    "\n",
    "def _int64_feature(value):\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def single_image_loader(input_path: str) -> np.array:\n",
    "    output_height = 256\n",
    "    output_width = 256\n",
    "    ds = dicom.dcmread(input_path)\n",
    "    ds[(0x0028, 0x0101)].value = 16\n",
    "    pix_arr = ds.pixel_array\n",
    "    pix_arr = [cv2.resize(slice_data, (output_width, output_height)) for slice_data in pix_arr]    \n",
    "    np_img = np.array(pix_arr)\n",
    "    np_img = np.transpose(np_img, (1, 2, 0))\n",
    "    return np_img \n",
    "\n",
    "def convert_to_record(image_data, label, file_name):\n",
    "    rows, columns, depth = image_data.shape\n",
    "    print(f\"Writting\")\n",
    "\n",
    "    writer = tf.io.TFRecordWriter(file_name)\n",
    "    image_raw = image_data.tobytes()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'height': _int64_feature(rows),\n",
    "        'width': _int64_feature(columns),\n",
    "        'depth': _int64_feature(depth),\n",
    "        'label': _int64_feature(int(label)),\n",
    "        'image_raw': _bytes_feature(image_raw)}))\n",
    "    \n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "path_list, label = extract_full_files_paths(file_path, \"metadata.csv\", processed_path)\n",
    "\n",
    "\n",
    "for i, path in enumerate(path_list):\n",
    "    img_data = single_image_loader(path)\n",
    "    convert_to_record(img_data, 1, os.path.join(processed_path, f\"record{i}.tfrecords\"))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def parse_tfrecord_fn(example_proto):\n",
    "    feature_description = {\n",
    "        'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    height = tf.cast(example['height'], tf.int32)\n",
    "    width = tf.cast(example['width'], tf.int32)\n",
    "    depth = tf.cast(example['depth'], tf.int32)\n",
    "    label = tf.cast(example['label'], tf.int32)\n",
    "\n",
    "    image_raw = tf.io.decode_raw(example['image_raw'], tf.int16)\n",
    "    image = tf.reshape(image_raw, (height, width, depth))\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# Create a dataset from the TFRecord file\n",
    "dataset = tf.data.TFRecordDataset([os.path.join(processed_path, \"test.tfrecords\")])\n",
    "\n",
    "# Map the parse_tfrecord_fn function to each element in the dataset\n",
    "dataset = dataset.map(parse_tfrecord_fn)\n",
    "\n",
    "# Create an iterator and get the next element\n",
    "iterator = iter(dataset)\n",
    "image, label = iterator.get_next()\n",
    "\n",
    "\n",
    "print(label)\n",
    "print(img_data.reshape(-1).shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../\"\n",
    "root_dir = os.path.abspath(root_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Medical_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
