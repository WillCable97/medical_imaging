{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../\"\n",
    "root_dir = os.path.abspath(root_dir)\n",
    "data_path = os.path.join(root_dir, \"data\")\n",
    "processed_path = os.path.join(data_path, \"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record1.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record10.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record11.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record12.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record13.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record14.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record15.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record16.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record17.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record18.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record19.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record2.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record20.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record21.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record22.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record23.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record24.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record25.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record26.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record27.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record28.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record29.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record3.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record30.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record31.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record32.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record33.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record34.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record35.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record36.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record37.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record38.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record39.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record4.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record40.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record41.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record42.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record43.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record44.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record45.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record46.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record47.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record48.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record49.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record5.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record50.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record51.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record6.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record7.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record8.tfrecords',\n",
       " 'c:\\\\Users\\\\willi\\\\Desktop\\\\AIPortfolio\\\\medical_imaging\\\\data\\\\processed\\\\record9.tfrecords']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list =[os.path.join(processed_path, x) for x in os.listdir(processed_path)]\n",
    "file_list = file_list[1:]#.gitkeep\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord_fn(example_proto):\n",
    "    feature_description = {\n",
    "        'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    height = tf.cast(example['height'], tf.int32)\n",
    "    width = tf.cast(example['width'], tf.int32)\n",
    "    depth = tf.cast(example['depth'], tf.int32)\n",
    "    label = tf.cast(example['label'], tf.int32)\n",
    "\n",
    "    image_raw = tf.io.decode_raw(example['image_raw'], tf.int32)\n",
    "    image_raw = tf.cast(image_raw, tf.float32)\n",
    "\n",
    "\n",
    "    image = tf.reshape(image_raw, (256, 256, 38))\n",
    "    label = tf.reshape(label, (1,))\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_set = tf.data.TFRecordDataset(file_list)\n",
    "tf_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(256, 256, 38), dtype=tf.float32, name=None), TensorSpec(shape=(1,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_set = tf_set.map(parse_tfrecord_fn)\n",
    "tf_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 38)\n"
     ]
    }
   ],
   "source": [
    "# Create an iterator and get the next element\n",
    "iterator = iter(tf_set)\n",
    "for i in range(1):\n",
    "    image, label = iterator.get_next()\n",
    "    print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(10, 256, 256, 38), dtype=tf.float32, name=None), TensorSpec(shape=(10, 1), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_set=tf_set.shuffle(1000).batch(10, drop_remainder=True)\n",
    "tf_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "class DenseOutput(keras.layers.Layer):\n",
    "    def __init__(self, output_classes:int):\n",
    "        super().__init__()\n",
    "        self.flatten_layer = keras.layers.Flatten()\n",
    "        self.dense_1 = keras.layers.Dense(4096, activation='relu')\n",
    "        self.dense_2 = keras.layers.Dense(4096, activation='relu')\n",
    "        self.output_layer = keras.layers.Dense(output_classes, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.flatten_layer(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvComponent(keras.layers.Layer):\n",
    "    def __init__(self, channel_count: int):\n",
    "        super().__init__()\n",
    "        self.conv_1 = keras.layers.Conv2D(channel_count, (3, 3), activation='relu', padding='same')\n",
    "        self.conv_2 = keras.layers.Conv2D(channel_count, (3, 3), activation='relu', padding='same')\n",
    "        self.pool_layer = keras.layers.MaxPooling2D((2,2), strides=(2,2))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.pool_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg16(keras.Model):\n",
    "    def __init__(self, output_classes:int):\n",
    "        super().__init__()\n",
    "        self.initial_pool = keras.layers.MaxPooling2D((5, 5), strides=(5, 5))\n",
    "        self.comp_1 = ConvComponent(64)\n",
    "        self.comp_2 = ConvComponent(128)\n",
    "        self.comp_3 = ConvComponent(256) #all these have only 2 components (slight deviation)\n",
    "        self.comp_4 = ConvComponent(512)\n",
    "        self.comp_5 = ConvComponent(512)\n",
    "        self.connected_layer = DenseOutput(output_classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = self.initial_pool(inputs)\n",
    "        inputs = self.comp_1(inputs)\n",
    "        inputs = self.comp_2(inputs)\n",
    "        inputs = self.comp_3(inputs)\n",
    "        inputs = self.comp_4(inputs)\n",
    "        inputs = self.comp_5(inputs)\n",
    "        inputs = self.connected_layer(inputs)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 569ms/step - loss: 1846.1052\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willi\\Anaconda3\\envs\\Medical_Env\\lib\\contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 347ms/step - loss: 0.2255\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 343ms/step - loss: 1.2864  \n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 334ms/step - loss: 0.0963\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 348ms/step - loss: 0.2460\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 352ms/step - loss: 0.1705\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 356ms/step - loss: 0.2261\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 317ms/step - loss: 0.0430\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 330ms/step - loss: 0.6215\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 319ms/step - loss: 0.2025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a3e6a1d5e0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = Vgg16(4)\n",
    "A.compile(\"adam\", keras.losses.SparseCategoricalCrossentropy())\n",
    "A.fit(tf_set, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in tf_set:\n",
    "    print(f\"1: {batch[0].shape}\")\n",
    "    print(f\"2: {batch[1].shape}\")\n",
    "    #print(f\"HEREL {batch[0]}\")\n",
    "    #brak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_set = tf.data.TFRecordDataset(file_list)\n",
    "tf_set = tf_set.map(parse_tfrecord_fn)\n",
    "#tf.convert_to_tensor(tf_set)\n",
    "#tf_set = tf_set.map(test_func)\n",
    "#tf_set = tf_set.map(lambda x, y: tf.ensure_shape(x, (256, 256, 38)))\n",
    "#tf_set = tf_set.map(lambda x, y: tf.cast(x, (256, 256, 38)))\n",
    "#tf_set=tf_set.shuffle(1000).batch(10, drop_remainder=True)\n",
    "#tf_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Medical_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
